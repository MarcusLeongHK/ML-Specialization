{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e47390c",
   "metadata": {},
   "source": [
    "# State Action Value Function Example\n",
    "\n",
    "In this Jupyter notebook, you can modify the mars rover example to see how the values of Q(s,a) will change depending on the rewards and discount factor changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c3b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15a3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify\n",
    "num_states = 6\n",
    "num_actions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b6e03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_left_reward = 50\n",
    "terminal_right_reward = 51\n",
    "each_step_reward = 0\n",
    "\n",
    "# Discount factor\n",
    "gamma = 0.9\n",
    "\n",
    "# Probability of going in the wrong direction\n",
    "misstep_prob = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6412db0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-5bca330d2b01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerate_visualization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterminal_left_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal_right_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach_step_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmisstep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Marcus\\programming\\machine learning specilization\\Machine-Learning-Specialization-Coursera\\C3 - Unsupervised Learning, Recommenders, Reinforcement Learning\\week3\\optional-labs\\utils.py\u001b[0m in \u001b[0;36mgenerate_visualization\u001b[1;34m(terminal_left_reward, terminal_right_reward, each_step_reward, gamma, misstep_prob)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mtransition_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_transition_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmisstep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0moptimal_policy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optimal_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[0mq_left_star\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_right_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_Q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimal_policy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Marcus\\programming\\machine learning specilization\\Machine-Learning-Specialization-Coursera\\C3 - Unsupervised Learning, Recommenders, Reinforcement Learning\\week3\\optional-labs\\utils.py\u001b[0m in \u001b[0;36mget_optimal_policy\u001b[1;34m(num_states, num_actions, rewards, transition_prob, gamma)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mpolicy_stable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimal_policy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0moptimal_policy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy_stable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimprove_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimal_policy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Marcus\\programming\\machine learning specilization\\Machine-Learning-Specialization-Coursera\\C3 - Unsupervised Learning, Recommenders, Reinforcement Learning\\week3\\optional-labs\\utils.py\u001b[0m in \u001b[0;36mevaluate_policy\u001b[1;34m(num_states, rewards, transition_prob, gamma, policy)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_Q_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_visualization(terminal_left_reward, terminal_right_reward, each_step_reward, gamma, misstep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ccd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
